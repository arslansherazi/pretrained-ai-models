{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34d8b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arslanhaider/.local/share/virtualenvs/pretrained-ai-models-vKmrXiHV/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# The main package that contains functions to use Hugging Face\n",
    "import transformers\n",
    "\n",
    "# Set to avoid warning messages.\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ca837c",
   "metadata": {},
   "source": [
    "## Reviewing the Pipeline\n",
    "\n",
    "Use the pipeline registry to look at available pipeline tasks and also explore a specific pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c0cfee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['audio-classification', 'automatic-speech-recognition', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-feature-extraction', 'image-segmentation', 'image-to-image', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection']\n"
     ]
    }
   ],
   "source": [
    "from transformers.pipelines import PIPELINE_REGISTRY\n",
    "\n",
    "# Get the list of tasks that are supported by Huggingface pipeline\n",
    "print(PIPELINE_REGISTRY.get_supported_tasks())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ede308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default Model for Sentiment Analysis: \n",
      "{'model': {'pt': ('distilbert/distilbert-base-uncased-finetuned-sst-2-english', '714eb0f'), 'tf': ('distilbert/distilbert-base-uncased-finetuned-sst-2-english', '714eb0f')}}\n"
     ]
    }
   ],
   "source": [
    "# Get information about a specific task\n",
    "print(\"\\nDefault Model for Sentiment Analysis: \")\n",
    "print(PIPELINE_REGISTRY.check_task('sentiment-analysis')[1].get('default'))\n",
    "\n",
    "# pt: pytorch, tf: tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb2f76",
   "metadata": {},
   "source": [
    "## Loading a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f892fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huggingface Cache directory is :  /Users/arslanhaider/.cache/huggingface/hub\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "\"\"\"Load a pipeline. This will download the model checkpoint from huggingface and cache it locally on disk. If model is already \n",
    "available in cache, it will simply use the cached version download will usually take a long time, depending on network bandwidth\"\"\"\n",
    "\n",
    "sentiment_classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Cache usually available at : ~\\.cache\\huggingface\\hub\n",
    "\n",
    "cache_dir = os.path.expanduser('~') + \"/.cache/huggingface/hub\"\n",
    "print(\"Huggingface Cache directory is : \", cache_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f95416",
   "metadata": {},
   "source": [
    "## Predicting Sentiment with Default Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_results = sentiment_classifier(\"This is a great course\")\n",
    "print(sentiment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "104c06f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9998070597648621}]\n"
     ]
    }
   ],
   "source": [
    "sentiment_results = sentiment_classifier(\"The download speed is really bad\")\n",
    "print(sentiment_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8154d932",
   "metadata": {},
   "source": [
    "## Using a custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e52dbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POS', 'score': 0.9920700192451477}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "cache_dir = os.path.expanduser('~') + \"/.cache/huggingface/hub\"\n",
    "\n",
    "sentiment_classifier = pipeline(task=\"sentiment-analysis\",\n",
    "                                model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "sentiment_result = sentiment_classifier(\"This is a great course\")\n",
    "\n",
    "print(sentiment_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pretrained-ai-models-vKmrXiHV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
